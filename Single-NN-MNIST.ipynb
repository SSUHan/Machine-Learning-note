{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist 자료를 가져오겠습니다\n",
    "### mnist 는 손글씨 데이터로 훈련용 55,000개, 테스트용 10,000개로 이루어져 있는 흑백 이미지 데이터이다\n",
    "### 20*20 픽셀로 정규화하고, 이미지의 중심을 계산해서 28*28 픽셀 크기로 이루어진 이미지 데이터이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.train.labels) # 55000 개의 데이터가 labeling 되어있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape # 55000 개의 데이터 인스턴스는 10개의 클래스를 갖는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(55000), Dimension(784)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(mnist.train.images).get_shape() # 이미지를 텐서로 바꿨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10])) # 784 픽셀벡터값을 대응하고, 이것이 10개의 클래스에 대해서 각각 존재하여 판단한다.\n",
    "b = tf.Variable(tf.zeros([10])) # 10개의 클래스에 대한 편향(bias) 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, 784]) # None 은 몇개의 인스턴스가 들어올지 모를때 열어두는 역할을 한다.\n",
    "y = tf.nn.softmax(tf.matmul(x, W)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기대하는 값과 실제값의 오차를 측정(Measure) 하기위한 여러가지 방법\n",
    "* 평균제곱오차\n",
    "* 유클리드 제곱거리\n",
    "* 교차 엔트로피 에러(cross entropy error)\n",
    "\n",
    "### 교차 엔트로피 에러는 y 와 y' 이 같을때 최솟값을 얻도록 수식이 정의되어 있다.\n",
    "### 따라서 이 값이 작아지는 방향으로 모델이 최적화를 시도하는 구조로 만들어져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_answer = tf.placeholder(\"float\", [None, 10]) # 실제 정답을 담고 있는 placeholder 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = - tf.reduce_sum(y_answer * tf.log(y)) # cross entropy 를 구하는 수식에 맞춰서 코드를 작성한 것 뿐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 엔트로피 비용함수와 경사 하강법(GradientDescent) 방법을 사용하면\n",
    "### 매 루프 반복마다 오차를 줄이기 위해서\n",
    "### 주어진 상황에서 W를 조금씩 변경시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  번째 트레이닝 상태에서 성능을 테스트 해봅니다\n",
      "0.2629\n",
      "100  번째 트레이닝 상태에서 성능을 테스트 해봅니다\n",
      "0.8955\n",
      "200  번째 트레이닝 상태에서 성능을 테스트 해봅니다\n",
      "0.9004\n",
      "300  번째 트레이닝 상태에서 성능을 테스트 해봅니다\n",
      "0.8816\n",
      "400  번째 트레이닝 상태에서 성능을 테스트 해봅니다\n",
      "0.9098\n",
      "500  번째 트레이닝 상태에서 성능을 테스트 해봅니다\n",
      "0.8971\n",
      "600  번째 트레이닝 상태에서 성능을 테스트 해봅니다\n",
      "0.9132\n",
      "700  번째 트레이닝 상태에서 성능을 테스트 해봅니다\n",
      "0.91\n",
      "800  번째 트레이닝 상태에서 성능을 테스트 해봅니다\n",
      "0.913\n",
      "900  번째 트레이닝 상태에서 성능을 테스트 해봅니다\n",
      "0.9144\n",
      "학습이 끝나고 최종 결과입니다.\n",
      "0.9114\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 기존에 쓰던 것은 deprecate 되었다\n",
    "    \n",
    "    for i in range(1000):\n",
    "        # 1000 번 학습해본다\n",
    "        batch_x, batch_y = mnist.train.next_batch(100) # training set 에서 100 개를 무작위로 뽑아온다\n",
    "        sess.run(train_step, feed_dict={x:batch_x, y_answer:batch_y})\n",
    "        if i % 100 == 0 :\n",
    "            # 100번마다 한번씩 상황을 지켜보자\n",
    "            print(i, \" 번째 트레이닝 상태에서 성능을 테스트 해봅니다\")\n",
    "            correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_answer, 1))\n",
    "            accurcy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            print(sess.run(accurcy, feed_dict={x:mnist.test.images, y_answer:mnist.test.labels}))\n",
    "    print(\"학습이 끝나고 최종 결과입니다.\")\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_answer, 1))\n",
    "    accurcy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(sess.run(accurcy, feed_dict={x:mnist.test.images, y_answer:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
